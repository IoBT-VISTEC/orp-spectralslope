{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "pjoin = os.path.join\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import (\n",
    "    create_if_no_exist, \n",
    "    load_configs, \n",
    "    plot_hypnogram,\n",
    "    intersect,\n",
    ")\n",
    "\n",
    "from orp_utils.const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'MESA'\n",
    "channel = 'EEG EEG3'\n",
    "results_version = 'lookup-table-v1'\n",
    "orp_version = 'v1'\n",
    "subjects_version = 'v1FOLD0'\n",
    "dset = VAL # TRAIN (construct new table) / VAL (only ranking)\n",
    "\n",
    "# To rank the power using all subjects in dset (ALL_SUBJ) or one subject (BY_SUBJ)\n",
    "running_type = ALL_SUBJ # ALL_SUBJ / BY_SUBJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_path = f'{ds_name}/extracted/{orp_version}/{channel}'\n",
    "csv_path = pjoin(global_path, 'csv')\n",
    "\n",
    "subjects_path = f'{ds_name}/subjects/{subjects_version}.npz'\n",
    "global_path, subjects_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dset == TRAIN and running_type == BY_SUBJ:\n",
    "    ans = str(input('Are you sure you want to construct lookup table for each subject separately? (y/n) : '))\n",
    "    if ans.lower() == 'y':\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception('''Change `dset` to VAL for running validation set (without constructing new table) \n",
    "        OR Change `running_type` to `ALL_SUBJ` to construct lookup table from all subjects.''')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking(\n",
    "        df, \n",
    "        col,\n",
    "        current_rank_df = [],\n",
    "        fig_path = '',\n",
    "    ): \n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.rcParams['axes.facecolor']='white'\n",
    "    plt.rcParams.update({'font.size': 22})\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    SUBJ_ID_COL = 'subj_id'\n",
    "    SAMPLE_ID_COL = 'sample_id'\n",
    "    ngroups = 10\n",
    "    nepochs = len(df)\n",
    "    nepochs_per_group = int(nepochs / ngroups)\n",
    "    # print('nepochs_per_group:', nepochs_per_group)\n",
    "    \n",
    "    values = df[col].values\n",
    "    deciles = [np.percentile(values, p) for p in range(10, 101, 10)]\n",
    "    #print(col, 'deciles:', deciles)\n",
    "    \n",
    "    #print(np.histogram(values))    \n",
    "    bins = np.arange(0.0, 1.1, 0.1)\n",
    "    freq, bins, patches = plt.hist(values, bins, rwidth=0.75, color='#5278B7')\n",
    "    bin_centers = np.diff(bins)*0.5 + bins[:-1]\n",
    "    nsamples = len(values)\n",
    "    \n",
    "    n = 0\n",
    "    for fr, x, patch in zip(freq, bin_centers, patches):\n",
    "        height = int(freq[n])\n",
    "        plt.annotate(\"{:.1f}\".format(height / nsamples * 100),\n",
    "                   xy = (x, height),             # top left corner of the histogram bar\n",
    "                   xytext = (0, 0.2),             # offsetting label position above its bar\n",
    "                   textcoords = \"offset points\", # Offset (in points) from the *xy* value\n",
    "                   ha = 'center', va = 'bottom'\n",
    "                   )\n",
    "        n += 1\n",
    "        \n",
    "    plt.ylabel('% of 3s samples')\n",
    "    plt.xlabel('Relative power spectrum')\n",
    "        \n",
    "    plt.title(f'{ds_name} | {col} ({nsamples} samples)', y=1.1)\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.1, nsamples + 1)\n",
    "    \n",
    "    if len(fig_path) > 0:\n",
    "        plt.savefig(pjoin(fig_path, f'{dset}_{col}.jpg'))\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "    \n",
    "    \"\"\"\n",
    "    print(np.histogram(values))\n",
    "    plt.hist(values[values > 20])\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    \n",
    "    RANK_COL = f'rank_{col}'\n",
    "    BIN_RANK_COL = f'{BIN_NUMBER_COL}_{col}'\n",
    "    \n",
    "    rank_df = df.sort_values(by=[col])\n",
    "    rank_df[RANK_COL] = range(nepochs)\n",
    "    rank_df[BIN_RANK_COL] = [math.floor(r) for r in rank_df[RANK_COL] / nepochs_per_group]\n",
    "    # print(np.unique(rank_df[BIN_RANK_COL], return_counts=True))\n",
    "\n",
    "    rank_df = rank_df.sort_values(by=[SUBJ_ID_COL, SAMPLE_ID_COL])\n",
    "     \n",
    "    if len(current_rank_df) == 0:\n",
    "        return rank_df\n",
    "    \n",
    "    else:\n",
    "        # append column to the existing one\n",
    "        for c in [RANK_COL, BIN_RANK_COL]:\n",
    "            current_rank_df[c] = rank_df[c]\n",
    "            \n",
    "        return current_rank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(subjects_path)\n",
    "files = data[dset]\n",
    "\n",
    "len(files), files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for idx, subject in enumerate(files):\n",
    "\n",
    "    print('subject:', subject)\n",
    "    outpath = pjoin(global_path, 'results', f'subjects-{subjects_version}')\n",
    "    \n",
    "    if running_type == BY_SUBJ:\n",
    "        outpath = pjoin(outpath, subject, results_version)\n",
    "    else:\n",
    "        outpath = pjoin(outpath, results_version)\n",
    "        \n",
    "    out_csv = pjoin(outpath, f'rank_powers_{dset}.csv')\n",
    "    out_json = pjoin(outpath, 'lookup-table.json')\n",
    "    create_if_no_exist(outpath)\n",
    "    \n",
    "    # read power and labels from csv\n",
    "    subj_df = pd.read_csv(pjoin(csv_path, subject+'.csv'))\n",
    "\n",
    "    if running_type == ALL_SUBJ:\n",
    "        df = df.append(subj_df)\n",
    "    else:\n",
    "        df = subj_df\n",
    "        \n",
    "    if running_type == BY_SUBJ or (running_type == ALL_SUBJ and idx == len(files) - 1):\n",
    "        \n",
    "        if running_type == BY_SUBJ:\n",
    "            assert len(df) == len(subj_df)\n",
    "    \n",
    "        col = 'delta'\n",
    "        rank_df = ranking(df, col, fig_path = outpath)\n",
    "\n",
    "        col = 'theta'\n",
    "        rank_df = ranking(df, col, rank_df, fig_path = outpath)\n",
    "        \n",
    "        col = 'alpha-sigma'\n",
    "        rank_df = ranking(df, col, rank_df, fig_path = outpath)\n",
    "\n",
    "        col = 'beta'\n",
    "        rank_df = ranking(df, col, rank_df, fig_path = outpath)\n",
    "        \n",
    "        # combine 4 digits\n",
    "        rank_df[BIN_NUMBER_COL] = rank_df[f'{BIN_NUMBER_COL}_delta'].map(str) + rank_df[f'{BIN_NUMBER_COL}_theta'].map(str) + rank_df[f'{BIN_NUMBER_COL}_alpha-sigma'].map(str) + rank_df[f'{BIN_NUMBER_COL}_beta'].map(str)\n",
    "        bin_numbers_rank, n_per_bin = np.unique(rank_df[BIN_NUMBER_COL], return_counts=True)\n",
    "\n",
    "        bin_numbers = ['{:04d}'.format(b) for b in range(10000)]\n",
    "        print(len(bin_numbers), 'bin numbers:', bin_numbers[:10], '...')\n",
    "\n",
    "        display(rank_df)\n",
    "        assert all([b in bin_numbers for b in bin_numbers_rank])\n",
    "        \n",
    "        print(f'saved ranking into {out_csv}')\n",
    "        rank_df.to_csv(out_csv)\n",
    "        \n",
    "\n",
    "        # contruct look-up dict { bin_number: ORP }\n",
    "\n",
    "        if dset == TRAIN:\n",
    "            ans = 'c'\n",
    "            if os.path.exists(out_json):\n",
    "                ans = str(input(f'{out_json} already exists. Type `l` to load or `c` to construct the new table.'))\n",
    "\n",
    "            if ans == 'l':\n",
    "                print(f'loading lookup table from {out_json}...')\n",
    "\n",
    "                with open(out_json, 'r') as j:\n",
    "                    lookup_dict = json.load(j)\n",
    "\n",
    "            elif ans == 'c':\n",
    "                print(f'constructing new lookup table...')\n",
    "                lookup_dict = {}\n",
    "                for b_num in bin_numbers:\n",
    "                    n_total = len(rank_df.loc[rank_df[BIN_NUMBER_COL] == b_num])\n",
    "                    n_awake = len(rank_df.loc[(rank_df[BIN_NUMBER_COL] == b_num) & (rank_df[WAKE_SLEEP_COL] == AWAKE)])\n",
    "\n",
    "                    if n_total < 10:\n",
    "                        prob = 0.5\n",
    "                    else:\n",
    "                        prob = n_awake / n_total\n",
    "\n",
    "                    print(b_num, 'total:', n_total, 'awake:', n_awake, 'prob:', prob)\n",
    "                    lookup_dict[b_num] = prob\n",
    "\n",
    "                with open(out_json, \"w\") as fout:\n",
    "                    json.dump(lookup_dict, fout, indent=4)\n",
    "\n",
    "            else:\n",
    "                raise Exception('invalid answer.')\n",
    "\n",
    "            print(len(lookup_dict.keys()))\n",
    "            print(lookup_dict)\n",
    "            print(out_json)\n",
    "\n",
    "        else:\n",
    "            print('ranking was done without constructing new table.')\n",
    "\n",
    "    \n",
    "    del subj_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
